#!/usr/bin/env python3
"""
JCRåˆ†åŒºè¡¨æ•°æ®åŒæ­¥è„šæœ¬
ä»ShowJCRä»“åº“è·å–æœ€æ–°çš„åˆ†åŒºè¡¨æ•°æ®å¹¶æ›´æ–°æœ¬åœ°æ•°æ®åº“
"""

import asyncio
import httpx
import sqlite3
import os
import pandas as pd
from pathlib import Path
import logging
from typing import Dict, List, Optional
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_sync.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DataSyncer:
    """æ•°æ®åŒæ­¥å™¨ç±»"""
    
    def __init__(self, db_path: str = "jcr.db"):
        self.db_path = db_path
        self.base_url = "https://raw.githubusercontent.com/hitfyd/ShowJCR/master/"
        self.data_folder = "ä¸­ç§‘é™¢åˆ†åŒºè¡¨åŠJCRåŸå§‹æ•°æ®æ–‡ä»¶"
        
        # æ•°æ®æºé…ç½®
        self.data_sources = {
            # JCRæ•°æ®
            "JCR2024": "JCR2024.csv",
            "JCR2023": "JCR2023.csv", 
            "JCR2022": "JCR2022.csv",
            
            # ä¸­ç§‘é™¢åˆ†åŒºè¡¨
            "FQBJCR2025": "2025å¹´ä¸­ç§‘é™¢å‡çº§ç‰ˆ.csv",
            "FQBJCR2023": "2023å¹´ä¸­ç§‘é™¢å‡çº§ç‰ˆ.csv",
            "FQBJCR2022": "2022å¹´ä¸­ç§‘é™¢å‡çº§ç‰ˆ.csv",
            
            # å›½é™…æœŸåˆŠé¢„è­¦åå•
            "GJQKYJMD2025": "å›½é™…æœŸåˆŠé¢„è­¦åå•2025.csv",
            "GJQKYJMD2024": "å›½é™…æœŸåˆŠé¢„è­¦åå•2024.csv",
            "GJQKYJMD2023": "å›½é™…æœŸåˆŠé¢„è­¦åå•2023.csv",
            "GJQKYJMD2021": "å›½é™…æœŸåˆŠé¢„è­¦åå•2021.csv",
            "GJQKYJMD2020": "å›½é™…æœŸåˆŠé¢„è­¦åå•2020.csv",
            
            # CCFæ¨è
            "CCF2022": "CCFæ¨èå›½é™…å­¦æœ¯æœŸåˆŠç›®å½•2022.csv",
            "CCFT2022": "è®¡ç®—é¢†åŸŸé«˜è´¨é‡ç§‘æŠ€æœŸåˆŠåˆ†çº§ç›®å½•2022.csv"
        }
    
    async def download_file(self, url: str, local_path: str) -> bool:
        """ä¸‹è½½æ–‡ä»¶"""
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                logger.info(f"æ­£åœ¨ä¸‹è½½: {url}")
                response = await client.get(url)
                response.raise_for_status()
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                Path(local_path).parent.mkdir(parents=True, exist_ok=True)
                
                # ä¿å­˜æ–‡ä»¶
                with open(local_path, 'wb') as f:
                    f.write(response.content)
                
                logger.info(f"æ–‡ä»¶å·²ä¿å­˜: {local_path}")
                return True
                
        except Exception as e:
            logger.error(f"ä¸‹è½½å¤±è´¥ {url}: {e}")
            return False
    
    def create_database_tables(self):
        """åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºå…ƒæ•°æ®è¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS sync_metadata (
            table_name TEXT PRIMARY KEY,
            last_updated TEXT,
            record_count INTEGER,
            file_hash TEXT
        )
        """)
        
        conn.commit()
        conn.close()
        logger.info("æ•°æ®åº“è¡¨ç»“æ„å·²åˆ›å»º")
    
    def import_csv_to_db(self, csv_path: str, table_name: str) -> bool:
        """å°†CSVæ–‡ä»¶å¯¼å…¥æ•°æ®åº“"""
        try:
            if not os.path.exists(csv_path):
                logger.warning(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
                return False
            
            # è¯»å–CSVæ–‡ä»¶
            try:
                # å°è¯•ä¸åŒçš„ç¼–ç 
                for encoding in ['utf-8', 'gbk', 'gb2312', 'utf-8-sig']:
                    try:
                        df = pd.read_csv(csv_path, encoding=encoding)
                        logger.info(f"ä½¿ç”¨ç¼–ç  {encoding} æˆåŠŸè¯»å–æ–‡ä»¶")
                        break
                    except UnicodeDecodeError:
                        continue
                else:
                    logger.error(f"æ— æ³•è¯»å–CSVæ–‡ä»¶ {csv_path}")
                    return False
                
            except Exception as e:
                logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥ {csv_path}: {e}")
                return False
            
            if df.empty:
                logger.warning(f"CSVæ–‡ä»¶ä¸ºç©º: {csv_path}")
                return False
            
            # è¿æ¥æ•°æ®åº“
            conn = sqlite3.connect(self.db_path)
            
            # åˆ é™¤ç°æœ‰è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            conn.execute(f"DROP TABLE IF EXISTS {table_name}")
            
            # å¯¼å…¥æ•°æ®
            df.to_sql(table_name, conn, if_exists='replace', index=False)
            
            # æ›´æ–°å…ƒæ•°æ®
            current_time = datetime.now().isoformat()
            record_count = len(df)
            
            cursor = conn.cursor()
            cursor.execute("""
            INSERT OR REPLACE INTO sync_metadata 
            (table_name, last_updated, record_count, file_hash)
            VALUES (?, ?, ?, ?)
            """, (table_name, current_time, record_count, ""))
            
            conn.commit()
            conn.close()
            
            logger.info(f"æˆåŠŸå¯¼å…¥ {table_name}: {record_count} æ¡è®°å½•")
            return True
            
        except Exception as e:
            logger.error(f"å¯¼å…¥CSVå¤±è´¥ {csv_path}: {e}")
            return False
    
    async def sync_all_data(self, force_download: bool = False) -> Dict[str, bool]:
        """åŒæ­¥æ‰€æœ‰æ•°æ®"""
        results = {}
        
        # åˆ›å»ºæ•°æ®åº“è¡¨
        self.create_database_tables()
        
        # åˆ›å»ºä¸´æ—¶ä¸‹è½½ç›®å½•
        download_dir = Path("temp_data")
        download_dir.mkdir(exist_ok=True)
        
        logger.info("å¼€å§‹åŒæ­¥JCRåˆ†åŒºè¡¨æ•°æ®...")
        
        for table_name, filename in self.data_sources.items():
            try:
                # æ„å»ºä¸‹è½½URL
                url = f"{self.base_url}{self.data_folder}/{filename}"
                local_path = download_dir / filename
                
                # ä¸‹è½½æ–‡ä»¶
                download_success = await self.download_file(url, str(local_path))
                
                if download_success:
                    # å¯¼å…¥åˆ°æ•°æ®åº“
                    import_success = self.import_csv_to_db(str(local_path), table_name)
                    results[table_name] = import_success
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if local_path.exists():
                        os.remove(local_path)
                        
                else:
                    results[table_name] = False
                    logger.error(f"æ•°æ®æº {table_name} åŒæ­¥å¤±è´¥")
                
            except Exception as e:
                logger.error(f"å¤„ç†æ•°æ®æº {table_name} æ—¶å‡ºé”™: {e}")
                results[table_name] = False
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if download_dir.exists():
            try:
                download_dir.rmdir()
            except:
                pass
        
        return results
    
    def get_sync_status(self) -> Dict[str, any]:
        """è·å–åŒæ­¥çŠ¶æ€"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("SELECT * FROM sync_metadata ORDER BY last_updated DESC")
            rows = cursor.fetchall()
            
            status = {
                "total_tables": len(rows),
                "tables": []
            }
            
            for row in rows:
                table_name, last_updated, record_count, file_hash = row
                status["tables"].append({
                    "name": table_name,
                    "last_updated": last_updated,
                    "record_count": record_count
                })
            
            conn.close()
            return status
            
        except Exception as e:
            logger.error(f"è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {e}")
            return {"total_tables": 0, "tables": []}
    
    def validate_data_integrity(self) -> Dict[str, any]:
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰è¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [table[0] for table in cursor.fetchall()]
            
            validation_results = {
                "total_tables": len(tables),
                "valid_tables": 0,
                "issues": []
            }
            
            for table in tables:
                if table == 'sync_metadata':
                    continue
                
                try:
                    # æ£€æŸ¥è¡¨ç»“æ„
                    cursor.execute(f"PRAGMA table_info({table})")
                    columns = [col[1] for col in cursor.fetchall()]
                    
                    # æ£€æŸ¥è®°å½•æ•°
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    count = cursor.fetchone()[0]
                    
                    if count > 0 and 'Journal' in columns:
                        validation_results["valid_tables"] += 1
                    else:
                        validation_results["issues"].append({
                            "table": table,
                            "issue": f"è¡¨ç»“æ„å¼‚å¸¸æˆ–æ— æ•°æ® (è®°å½•æ•°: {count})"
                        })
                        
                except Exception as e:
                    validation_results["issues"].append({
                        "table": table,
                        "issue": f"éªŒè¯å¤±è´¥: {e}"
                    })
            
            conn.close()
            return validation_results
            
        except Exception as e:
            logger.error(f"æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}")
            return {"total_tables": 0, "valid_tables": 0, "issues": [{"table": "unknown", "issue": str(e)}]}

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ JCRåˆ†åŒºè¡¨æ•°æ®åŒæ­¥å·¥å…·")
    print("=" * 50)
    
    syncer = DataSyncer()
    
    while True:
        print("\nğŸ“‹ å¯ç”¨æ“ä½œ:")
        print("1. åŒæ­¥æ‰€æœ‰æ•°æ®")
        print("2. æŸ¥çœ‹åŒæ­¥çŠ¶æ€")
        print("3. éªŒè¯æ•°æ®å®Œæ•´æ€§")
        print("4. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-4): ").strip()
        
        if choice == "1":
            print("\nğŸš€ å¼€å§‹åŒæ­¥æ•°æ®...")
            results = await syncer.sync_all_data()
            
            success_count = sum(1 for success in results.values() if success)
            total_count = len(results)
            
            print(f"\nğŸ“Š åŒæ­¥å®Œæˆ: {success_count}/{total_count} æˆåŠŸ")
            
            for table_name, success in results.items():
                status = "âœ…" if success else "âŒ"
                print(f"  {status} {table_name}")
        
        elif choice == "2":
            print("\nğŸ“Š åŒæ­¥çŠ¶æ€:")
            status = syncer.get_sync_status()
            
            print(f"æ€»è¡¨æ•°: {status['total_tables']}")
            
            for table_info in status["tables"]:
                print(f"  ğŸ“‹ {table_info['name']}")
                print(f"      æœ€åæ›´æ–°: {table_info['last_updated']}")
                print(f"      è®°å½•æ•°: {table_info['record_count']}")
        
        elif choice == "3":
            print("\nğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§...")
            validation = syncer.validate_data_integrity()
            
            print(f"æ€»è¡¨æ•°: {validation['total_tables']}")
            print(f"æœ‰æ•ˆè¡¨æ•°: {validation['valid_tables']}")
            
            if validation['issues']:
                print("\nâš ï¸ å‘ç°é—®é¢˜:")
                for issue in validation['issues']:
                    print(f"  â€¢ {issue['table']}: {issue['issue']}")
            else:
                print("âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        
        elif choice == "4":
            print("ğŸ‘‹ å†è§ï¼")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    asyncio.run(main()) 