import asyncio
import sqlite3
import os
import json
from typing import Optional, Dict, List, Any
from dataclasses import dataclass
import httpx
from pathlib import Path

from mcp.server.fastmcp import FastMCP
from mcp.server.fastmcp import Context

# é…ç½®å¸¸é‡ - ä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
SCRIPT_DIR = Path(__file__).parent.absolute()
DATABASE_PATH = str(SCRIPT_DIR / "jcr.db")
DATA_UPDATE_URL = "https://raw.githubusercontent.com/hitfyd/ShowJCR/master/ä¸­ç§‘é™¢åˆ†åŒºè¡¨åŠJCRåŸå§‹æ•°æ®æ–‡ä»¶/"

@dataclass
class JournalInfo:
    """æœŸåˆŠä¿¡æ¯æ•°æ®ç±»"""
    journal_name: str
    impact_factor: Optional[float] = None
    partition: Optional[str] = None
    category: Optional[str] = None
    warning_status: Optional[str] = None
    ccf_level: Optional[str] = None
    year: Optional[str] = None

class JCRDatabase:
    """JCRæ•°æ®åº“ç®¡ç†ç±»"""
    
    def __init__(self, db_path: str = DATABASE_PATH):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        if not os.path.exists(self.db_path):
            # å¦‚æœæ•°æ®åº“ä¸å­˜åœ¨ï¼Œåˆ›å»ºåŸºæœ¬è¡¨ç»“æ„
            conn = sqlite3.connect(self.db_path)
            conn.close()
    
    def search_journal(self, journal_name: str, year: Optional[str] = None) -> List[JournalInfo]:
        """æœç´¢æœŸåˆŠä¿¡æ¯"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        results = []
        try:
            # è·å–æ‰€æœ‰è¡¨å
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [table[0] for table in cursor.fetchall()]
            
            # åœ¨å„ä¸ªè¡¨ä¸­æœç´¢æœŸåˆŠ
            for table in tables:
                try:
                    # æ£€æŸ¥è¡¨ç»“æ„
                    cursor.execute(f"PRAGMA table_info({table})")
                    columns = [col[1] for col in cursor.fetchall()]
                    
                    if 'Journal' not in columns:
                        continue
                    
                    # æ„å»ºæŸ¥è¯¢è¯­å¥
                    query = f"SELECT * FROM {table} WHERE Journal LIKE ? COLLATE NOCASE"
                    cursor.execute(query, (f"%{journal_name}%",))
                    
                    rows = cursor.fetchall()
                    column_names = [description[0] for description in cursor.description]
                    
                    for row in rows:
                        row_dict = dict(zip(column_names, row))
                        journal_info = self._parse_journal_info(row_dict, table)
                        if journal_info:
                            results.append(journal_info)
                
                except sqlite3.Error:
                    continue
        
        finally:
            conn.close()
        
        return results
    
    def _parse_journal_info(self, row_dict: Dict, table_name: str) -> Optional[JournalInfo]:
        """è§£ææ•°æ®åº“è¡Œä¸ºæœŸåˆŠä¿¡æ¯å¯¹è±¡"""
        try:
            journal_name = row_dict.get('Journal', '')
            
            # æ ¹æ®è¡¨ååˆ¤æ–­æ•°æ®ç±»å‹å’Œå¹´ä»½
            impact_factor = None
            partition = None
            category = None
            warning_status = None
            ccf_level = None
            year = None
            
            # è¾…åŠ©å‡½æ•°ï¼šæŸ¥æ‰¾åŒ…å«å…³é”®å­—çš„åˆ—
            def find_column_value(keywords):
                for key, value in row_dict.items():
                    for keyword in keywords:
                        if keyword.lower() in key.lower():
                            return value
                return None
            
            # è§£æå¹´ä»½
            if 'JCR' in table_name and 'FQBJCR' not in table_name:
                year = table_name.replace('JCR', '')
                # åŠ¨æ€æŸ¥æ‰¾ IF å’Œ Quartile åˆ—ï¼ˆåˆ—åå¯èƒ½æ˜¯ IF(2022)ã€IF Quartile(2022) ç­‰æ ¼å¼ï¼‰
                impact_factor = find_column_value(['IF(', 'IF '])
                partition = find_column_value(['Quartile', 'åˆ†åŒº'])
                category = find_column_value(['Category', 'ç±»åˆ«', 'SCIE', 'SSCI'])
            
            elif 'FQBJCR' in table_name:
                year = table_name.replace('FQBJCR', '')
                partition = find_column_value(['å¤§ç±»åˆ†åŒº', 'åˆ†åŒº', 'Partition'])
                category = find_column_value(['å­¦ç§‘', 'Subject', 'å¤§ç±»'])
                impact_factor = find_column_value(['IF', 'å½±å“å› å­'])
            
            elif 'GJQKYJMD' in table_name:
                year = table_name.replace('GJQKYJMD', '')
                warning_status = find_column_value(['é¢„è­¦ç­‰çº§', 'é¢„è­¦åŸå› ', 'Warning'])
            
            elif 'CCF' in table_name:
                year = table_name.replace('CCF', '')
                ccf_level = find_column_value(['CCFæ¨èç±»å‹', 'CCF', 'ç­‰çº§'])
                category = find_column_value(['é¢†åŸŸ', 'Field'])
            
            return JournalInfo(
                journal_name=journal_name,
                impact_factor=impact_factor,
                partition=partition,
                category=category,
                warning_status=warning_status,
                ccf_level=ccf_level,
                year=year
            )
        
        except Exception:
            return None

# åˆå§‹åŒ–FastMCPæœåŠ¡å™¨
app = FastMCP("jcr-partition-server", port=8080)
db = JCRDatabase()

@app.tool()
async def search_journal(journal_name: str, year: Optional[str] = None) -> str:
    """
    æœç´¢æœŸåˆŠä¿¡æ¯ï¼ŒåŒ…æ‹¬å½±å“å› å­ã€åˆ†åŒºã€é¢„è­¦çŠ¶æ€ç­‰
    
    Args:
        journal_name: æœŸåˆŠåç§°ï¼ˆæ”¯æŒæ¨¡ç³Šæœç´¢ï¼‰
        year: æŒ‡å®šå¹´ä»½ï¼ˆå¯é€‰ï¼Œå¦‚2025ã€2024ã€2023ç­‰ï¼‰
    
    Returns:
        æœŸåˆŠçš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬å„å¹´ä»½çš„åˆ†åŒºã€å½±å“å› å­ç­‰æ•°æ®
    """
    try:
        results = db.search_journal(journal_name, year)
        
        if not results:
            return f"æœªæ‰¾åˆ°æœŸåˆŠ '{journal_name}' çš„ç›¸å…³ä¿¡æ¯"
        
        # æŒ‰æœŸåˆŠåç§°å’Œå¹´ä»½åˆ†ç»„æ•´ç†ç»“æœ
        grouped_results = {}
        for result in results:
            key = result.journal_name
            if key not in grouped_results:
                grouped_results[key] = []
            grouped_results[key].append(result)
        
        output = []
        for journal, infos in grouped_results.items():
            output.append(f"\nğŸ“š æœŸåˆŠåç§°: {journal}")
            output.append("=" * 50)
            
            # æŒ‰å¹´ä»½æ’åº
            infos.sort(key=lambda x: x.year or "0000", reverse=True)
            
            for info in infos:
                year_str = f"ã€{info.year}å¹´ã€‘" if info.year else "ã€æœªçŸ¥å¹´ä»½ã€‘"
                output.append(f"\n{year_str}")
                
                if info.impact_factor:
                    output.append(f"  ğŸ“Š å½±å“å› å­: {info.impact_factor}")
                
                if info.partition:
                    output.append(f"  ğŸ† åˆ†åŒº: {info.partition}")
                
                if info.category:
                    output.append(f"  ğŸ“– å­¦ç§‘ç±»åˆ«: {info.category}")
                
                if info.warning_status:
                    output.append(f"  âš ï¸ é¢„è­¦çŠ¶æ€: {info.warning_status}")
                
                if info.ccf_level:
                    output.append(f"  ğŸ… CCFæ¨èç­‰çº§: {info.ccf_level}")
        
        return "\n".join(output)
    
    except Exception as e:
        return f"æŸ¥è¯¢å‡ºé”™: {str(e)}"

@app.tool()
async def get_partition_trends(journal_name: str) -> str:
    """
    è·å–æœŸåˆŠåˆ†åŒºå˜åŒ–è¶‹åŠ¿
    
    Args:
        journal_name: æœŸåˆŠåç§°
    
    Returns:
        æœŸåˆŠå†å¹´åˆ†åŒºå˜åŒ–è¶‹åŠ¿åˆ†æ
    """
    try:
        results = db.search_journal(journal_name)
        
        if not results:
            return f"æœªæ‰¾åˆ°æœŸåˆŠ '{journal_name}' çš„ç›¸å…³ä¿¡æ¯"
        
        # æå–åˆ†åŒºä¿¡æ¯
        partition_data = []
        for result in results:
            if result.partition and result.year:
                partition_data.append((result.year, result.partition, result.journal_name))
        
        if not partition_data:
            return f"æœªæ‰¾åˆ°æœŸåˆŠ '{journal_name}' çš„åˆ†åŒºä¿¡æ¯"
        
        # æŒ‰å¹´ä»½æ’åº
        partition_data.sort(key=lambda x: x[0])
        
        output = [f"ğŸ“ˆ æœŸåˆŠåˆ†åŒºå˜åŒ–è¶‹åŠ¿åˆ†æ"]
        output.append("=" * 40)
        
        for year, partition, journal in partition_data:
            output.append(f"{year}å¹´: {partition}")
        
        # ç®€å•è¶‹åŠ¿åˆ†æ
        if len(partition_data) > 1:
            output.append("\nğŸ“Š è¶‹åŠ¿åˆ†æ:")
            first_partition = partition_data[0][1]
            last_partition = partition_data[-1][1]
            
            if "1åŒº" in last_partition or "Q1" in last_partition:
                output.append("âœ… è¯¥æœŸåˆŠä¿æŒåœ¨é¡¶çº§åˆ†åŒº")
            elif "4åŒº" in last_partition or "Q4" in last_partition:
                output.append("âš ï¸ è¯¥æœŸåˆŠåˆ†åŒºè¾ƒä½ï¼Œå‘è¡¨éœ€è°¨æ…")
            else:
                output.append("ğŸ“Š è¯¥æœŸåˆŠåˆ†åŒºç¨³å®šï¼Œå±äºä¸­ç­‰æ°´å¹³")
        
        return "\n".join(output)
    
    except Exception as e:
        return f"åˆ†æå‡ºé”™: {str(e)}"

@app.tool()
async def check_warning_journals(keywords: Optional[str] = None) -> str:
    """
    æŸ¥è¯¢å›½é™…æœŸåˆŠé¢„è­¦åå•
    
    Args:
        keywords: å…³é”®è¯ï¼ˆå¯é€‰ï¼Œç”¨äºç­›é€‰ç‰¹å®šæœŸåˆŠï¼‰
    
    Returns:
        é¢„è­¦æœŸåˆŠåˆ—è¡¨åŠå…¶é¢„è­¦åŸå› 
    """
    try:
        conn = sqlite3.connect(db.db_path)
        cursor = conn.cursor()
        
        # è·å–é¢„è­¦è¡¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'GJQKYJMD%'")
        warning_tables = [table[0] for table in cursor.fetchall()]
        
        if not warning_tables:
            return "æœªæ‰¾åˆ°é¢„è­¦æœŸåˆŠæ•°æ®è¡¨"
        
        output = ["ğŸš¨ å›½é™…æœŸåˆŠé¢„è­¦åå•æŸ¥è¯¢ç»“æœ"]
        output.append("=" * 40)
        
        for table in sorted(warning_tables, reverse=True):
            year = table.replace('GJQKYJMD', '')
            output.append(f"\nğŸ“… {year}å¹´é¢„è­¦åå•:")
            
            query = f"SELECT * FROM {table}"
            params = []
            
            if keywords:
                query += " WHERE Journal LIKE ? COLLATE NOCASE"
                params.append(f"%{keywords}%")
            
            cursor.execute(query, params)
            rows = cursor.fetchall()
            column_names = [description[0] for description in cursor.description]
            
            if rows:
                for row in rows:
                    row_dict = dict(zip(column_names, row))
                    journal_name = row_dict.get('Journal', 'æœªçŸ¥æœŸåˆŠ')
                    warning_reason = row_dict.get('é¢„è­¦åŸå› ', row_dict.get('é¢„è­¦ç­‰çº§', 'æœªçŸ¥åŸå› '))
                    output.append(f"  â€¢ {journal_name}: {warning_reason}")
            else:
                if keywords:
                    output.append(f"  æ— åŒ¹é… '{keywords}' çš„é¢„è­¦æœŸåˆŠ")
                else:
                    output.append("  è¯¥å¹´åº¦æ— é¢„è­¦æœŸåˆŠæ•°æ®")
        
        conn.close()
        return "\n".join(output)
    
    except Exception as e:
        return f"æŸ¥è¯¢é¢„è­¦æœŸåˆŠå‡ºé”™: {str(e)}"

@app.tool()
async def compare_journals(journal_list: str) -> str:
    """
    æ¯”è¾ƒå¤šä¸ªæœŸåˆŠçš„ç»¼åˆä¿¡æ¯
    
    Args:
        journal_list: æœŸåˆŠåç§°åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚"Nature,Science,Cell"
    
    Returns:
        å¤šä¸ªæœŸåˆŠçš„å¯¹æ¯”åˆ†æç»“æœ
    """
    try:
        journals = [j.strip() for j in journal_list.split(',')]
        
        if len(journals) < 2:
            return "è¯·è‡³å°‘æä¾›2ä¸ªæœŸåˆŠåç§°è¿›è¡Œæ¯”è¾ƒ"
        
        output = ["ğŸ“Š æœŸåˆŠå¯¹æ¯”åˆ†æç»“æœ"]
        output.append("=" * 50)
        
        all_results = {}
        for journal in journals:
            results = db.search_journal(journal)
            all_results[journal] = results
        
        # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
        output.append(f"\n{'æœŸåˆŠåç§°':<30} {'æœ€æ–°å½±å“å› å­':<15} {'æœ€æ–°åˆ†åŒº':<15} {'é¢„è­¦çŠ¶æ€':<15}")
        output.append("-" * 80)
        
        for journal, results in all_results.items():
            if not results:
                output.append(f"{journal:<30} {'æ— æ•°æ®':<15} {'æ— æ•°æ®':<15} {'æ— æ•°æ®':<15}")
                continue
            
            # è·å–æœ€æ–°æ•°æ®
            latest_if = "æ— æ•°æ®"
            latest_partition = "æ— æ•°æ®"
            warning_status = "æ­£å¸¸"
            
            for result in results:
                if result.impact_factor:
                    latest_if = str(result.impact_factor)
                if result.partition:
                    latest_partition = result.partition
                if result.warning_status:
                    warning_status = "âš ï¸é¢„è­¦"
                    break
            
            output.append(f"{journal:<30} {latest_if:<15} {latest_partition:<15} {warning_status:<15}")
        
        # æ¨èå»ºè®®
        output.append("\nğŸ’¡ æŠ•ç¨¿å»ºè®®:")
        for journal, results in all_results.items():
            if results:
                has_warning = any(r.warning_status for r in results)
                if has_warning:
                    output.append(f"  âŒ {journal}: è¯¥æœŸåˆŠåœ¨é¢„è­¦åå•ä¸­ï¼Œä¸å»ºè®®æŠ•ç¨¿")
                else:
                    latest_partition = None
                    for result in results:
                        if result.partition:
                            latest_partition = result.partition
                            break
                    
                    if latest_partition and ("1åŒº" in latest_partition or "Q1" in latest_partition):
                        output.append(f"  â­ {journal}: é¡¶çº§æœŸåˆŠï¼Œå¼ºçƒˆæ¨è")
                    elif latest_partition and ("2åŒº" in latest_partition or "Q2" in latest_partition):
                        output.append(f"  âœ… {journal}: ä¼˜è´¨æœŸåˆŠï¼Œæ¨èæŠ•ç¨¿")
                    else:
                        output.append(f"  ğŸ“ {journal}: å¯è€ƒè™‘æŠ•ç¨¿")
        
        return "\n".join(output)
    
    except Exception as e:
        return f"æ¯”è¾ƒåˆ†æå‡ºé”™: {str(e)}"

@app.tool()
async def filter_journals(
    partition: Optional[str] = None,
    min_if: Optional[float] = None,
    max_if: Optional[float] = None,
    category: Optional[str] = None,
    is_top: Optional[bool] = None,
    is_oa: Optional[bool] = None,
    year: str = "2025",
    limit: int = 50
) -> str:
    """
    æŒ‰æ¡ä»¶ç­›é€‰æœŸåˆŠåˆ—è¡¨

    Args:
        partition: åˆ†åŒºç­›é€‰ï¼Œå¦‚"1åŒº"ã€"2åŒº"ã€"Q1"ã€"Q2"ç­‰
        min_if: æœ€å°å½±å“å› å­
        max_if: æœ€å¤§å½±å“å› å­
        category: å­¦ç§‘å¤§ç±»ï¼Œå¦‚"è®¡ç®—æœºç§‘å­¦"ã€"åŒ»å­¦"ã€"åŒ–å­¦"ç­‰
        is_top: æ˜¯å¦TopæœŸåˆŠï¼ˆä»…å¯¹ä¸­ç§‘é™¢åˆ†åŒºæœ‰æ•ˆï¼‰
        is_oa: æ˜¯å¦å¼€æ”¾è·å–æœŸåˆŠ
        year: æ•°æ®å¹´ä»½ï¼Œé»˜è®¤2025
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼Œé»˜è®¤50

    Returns:
        ç¬¦åˆæ¡ä»¶çš„æœŸåˆŠåˆ—è¡¨
    """
    try:
        conn = sqlite3.connect(db.db_path)
        cursor = conn.cursor()

        # ä¼˜å…ˆä½¿ç”¨ä¸­ç§‘é™¢åˆ†åŒºè¡¨ï¼ˆFQBJCRï¼‰
        table_name = f"FQBJCR{year}"

        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
        if not cursor.fetchone():
            # å°è¯•ä½¿ç”¨JCRè¡¨
            table_name = f"JCR{year}"
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))
            if not cursor.fetchone():
                conn.close()
                return f"æœªæ‰¾åˆ°{year}å¹´çš„æœŸåˆŠæ•°æ®è¡¨"

        # è·å–è¡¨ç»“æ„
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = [col[1] for col in cursor.fetchall()]

        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = []
        params = []

        # åˆ†åŒºç­›é€‰
        if partition:
            if 'å¤§ç±»åˆ†åŒº' in columns:
                conditions.append("å¤§ç±»åˆ†åŒº LIKE ?")
                params.append(f"%{partition}%")
            elif any('Quartile' in col for col in columns):
                quartile_col = [col for col in columns if 'Quartile' in col][0]
                conditions.append(f'"{quartile_col}" LIKE ?')
                params.append(f"%{partition}%")

        # å­¦ç§‘ç­›é€‰
        if category:
            if 'å¤§ç±»' in columns:
                conditions.append("å¤§ç±» LIKE ?")
                params.append(f"%{category}%")
            elif 'Category' in columns:
                conditions.append("Category LIKE ?")
                params.append(f"%{category}%")

        # TopæœŸåˆŠç­›é€‰
        if is_top is not None and 'Top' in columns:
            if is_top:
                conditions.append("Top = 'æ˜¯'")
            else:
                conditions.append("(Top = 'å¦' OR Top IS NULL)")

        # OAç­›é€‰
        if is_oa is not None and 'Open Access' in columns:
            if is_oa:
                conditions.append('"Open Access" IS NOT NULL AND "Open Access" != \'\'')
            else:
                conditions.append('("Open Access" IS NULL OR "Open Access" = \'\')')

        # æ„å»ºSQL
        query = f"SELECT * FROM {table_name}"
        if conditions:
            query += " WHERE " + " AND ".join(conditions)
        query += f" LIMIT {limit}"

        cursor.execute(query, params)
        rows = cursor.fetchall()
        column_names = [desc[0] for desc in cursor.description]

        if not rows:
            conn.close()
            return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æœŸåˆŠ"

        # å½±å“å› å­ç­›é€‰ï¼ˆåå¤„ç†ï¼Œå› ä¸ºåˆ—ååŠ¨æ€ï¼‰
        results = []
        for row in rows:
            row_dict = dict(zip(column_names, row))

            # æŸ¥æ‰¾å½±å“å› å­
            if_value = None
            for key, value in row_dict.items():
                if 'IF' in key and value is not None:
                    try:
                        if_value = float(value)
                        break
                    except (ValueError, TypeError):
                        continue

            # å½±å“å› å­èŒƒå›´ç­›é€‰
            if min_if is not None and (if_value is None or if_value < min_if):
                continue
            if max_if is not None and (if_value is None or if_value > max_if):
                continue

            results.append(row_dict)

        conn.close()

        if not results:
            return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æœŸåˆŠ"

        # æ ¼å¼åŒ–è¾“å‡º
        output = [f"ğŸ” ç­›é€‰ç»“æœï¼ˆ{year}å¹´æ•°æ®ï¼Œå…±{len(results)}æ¡ï¼‰"]
        output.append("=" * 50)

        for i, row in enumerate(results[:limit], 1):
            journal = row.get('Journal', 'æœªçŸ¥')
            partition_val = row.get('å¤§ç±»åˆ†åŒº', row.get([k for k in row.keys() if 'Quartile' in k][0] if any('Quartile' in k for k in row.keys()) else '', ''))
            category_val = row.get('å¤§ç±»', row.get('Category', ''))
            top_val = row.get('Top', '')

            # æŸ¥æ‰¾IF
            if_val = ''
            for key, value in row.items():
                if 'IF' in key and value:
                    if_val = str(value)
                    break

            output.append(f"\n{i}. {journal}")
            if partition_val:
                output.append(f"   åˆ†åŒº: {partition_val}")
            if if_val:
                output.append(f"   IF: {if_val}")
            if category_val:
                output.append(f"   å­¦ç§‘: {category_val}")
            if top_val == 'æ˜¯':
                output.append(f"   â­ TopæœŸåˆŠ")

        return "\n".join(output)

    except Exception as e:
        return f"ç­›é€‰å‡ºé”™: {str(e)}"


@app.tool()
async def batch_query_journals(journal_names: str, output_format: str = "text") -> str:
    """
    æ‰¹é‡æŸ¥è¯¢å¤šä¸ªæœŸåˆŠä¿¡æ¯ï¼Œæ”¯æŒå¯¼å‡ºä¸ºJSONæ ¼å¼

    Args:
        journal_names: æœŸåˆŠåç§°åˆ—è¡¨ï¼Œç”¨é€—å·æˆ–æ¢è¡Œåˆ†éš”
        output_format: è¾“å‡ºæ ¼å¼ï¼Œ"text"ä¸ºæ–‡æœ¬æ ¼å¼ï¼Œ"json"ä¸ºJSONæ ¼å¼ï¼ˆæ–¹ä¾¿å¯¼å‡ºï¼‰

    Returns:
        æ‰¹é‡æŸ¥è¯¢ç»“æœ
    """
    try:
        # è§£ææœŸåˆŠåç§°åˆ—è¡¨
        names = []
        for name in journal_names.replace('\n', ',').split(','):
            name = name.strip()
            if name:
                names.append(name)

        if not names:
            return "è¯·æä¾›è‡³å°‘ä¸€ä¸ªæœŸåˆŠåç§°"

        results_data = []

        for name in names:
            journal_results = db.search_journal(name)

            if journal_results:
                # è·å–æœ€æ–°æ•°æ®
                latest_info = {
                    "query": name,
                    "found": True,
                    "journal_name": journal_results[0].journal_name,
                    "impact_factor": None,
                    "partition": None,
                    "category": None,
                    "warning": False,
                    "years_data": []
                }

                for r in journal_results:
                    year_data = {"year": r.year}
                    if r.impact_factor:
                        year_data["if"] = r.impact_factor
                        if latest_info["impact_factor"] is None:
                            latest_info["impact_factor"] = r.impact_factor
                    if r.partition:
                        year_data["partition"] = r.partition
                        if latest_info["partition"] is None:
                            latest_info["partition"] = r.partition
                    if r.category:
                        year_data["category"] = r.category
                        if latest_info["category"] is None:
                            latest_info["category"] = r.category
                    if r.warning_status:
                        year_data["warning"] = r.warning_status
                        latest_info["warning"] = True

                    latest_info["years_data"].append(year_data)

                results_data.append(latest_info)
            else:
                results_data.append({
                    "query": name,
                    "found": False
                })

        # è¾“å‡ºæ ¼å¼
        if output_format.lower() == "json":
            return json.dumps(results_data, ensure_ascii=False, indent=2)

        # æ–‡æœ¬æ ¼å¼è¾“å‡º
        output = [f"ğŸ“‹ æ‰¹é‡æŸ¥è¯¢ç»“æœï¼ˆå…±{len(names)}ä¸ªæœŸåˆŠï¼‰"]
        output.append("=" * 50)

        for data in results_data:
            if data["found"]:
                output.append(f"\nâœ… {data['journal_name']}")
                if data["impact_factor"]:
                    output.append(f"   IF: {data['impact_factor']}")
                if data["partition"]:
                    output.append(f"   åˆ†åŒº: {data['partition']}")
                if data["category"]:
                    output.append(f"   å­¦ç§‘: {data['category']}")
                if data["warning"]:
                    output.append(f"   âš ï¸ å­˜åœ¨é¢„è­¦è®°å½•")
            else:
                output.append(f"\nâŒ {data['query']} - æœªæ‰¾åˆ°")

        output.append("\n" + "=" * 50)
        output.append("ğŸ’¡ æç¤º: ä½¿ç”¨ output_format='json' å¯è·å–JSONæ ¼å¼ï¼Œæ–¹ä¾¿å¯¼å‡ºåˆ°Excel")

        return "\n".join(output)

    except Exception as e:
        return f"æ‰¹é‡æŸ¥è¯¢å‡ºé”™: {str(e)}"


@app.tool()
async def check_data_update() -> str:
    """
    æ£€æŸ¥ShowJCRæ•°æ®æºæ˜¯å¦æœ‰æ›´æ–°

    Returns:
        æ•°æ®æºæ›´æ–°çŠ¶æ€ä¿¡æ¯
    """
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            # æ£€æŸ¥è¿œç¨‹æ•°æ®åº“æ–‡ä»¶
            db_url = "https://raw.githubusercontent.com/hitfyd/ShowJCR/master/ä¸­ç§‘é™¢åˆ†åŒºè¡¨åŠJCRåŸå§‹æ•°æ®æ–‡ä»¶/jcr.db"

            response = await client.head(db_url, follow_redirects=True)

            if response.status_code == 200:
                remote_size = int(response.headers.get('content-length', 0))
                remote_modified = response.headers.get('last-modified', 'æœªçŸ¥')

                # è·å–æœ¬åœ°æ–‡ä»¶ä¿¡æ¯
                local_size = 0
                local_modified = "æœªçŸ¥"
                if os.path.exists(DATABASE_PATH):
                    local_size = os.path.getsize(DATABASE_PATH)
                    local_modified = os.path.getmtime(DATABASE_PATH)
                    from datetime import datetime
                    local_modified = datetime.fromtimestamp(local_modified).strftime('%Y-%m-%d %H:%M:%S')

                output = ["ğŸ”„ æ•°æ®æ›´æ–°æ£€æŸ¥"]
                output.append("=" * 40)
                output.append(f"\nğŸ“¡ è¿œç¨‹æ•°æ®æº:")
                output.append(f"   å¤§å°: {remote_size / 1024 / 1024:.2f} MB")
                output.append(f"   æ›´æ–°æ—¶é—´: {remote_modified}")
                output.append(f"\nğŸ’¾ æœ¬åœ°æ•°æ®åº“:")
                output.append(f"   å¤§å°: {local_size / 1024 / 1024:.2f} MB")
                output.append(f"   æ›´æ–°æ—¶é—´: {local_modified}")

                if remote_size != local_size:
                    output.append(f"\nâš ï¸ æ£€æµ‹åˆ°æ•°æ®å¯èƒ½æœ‰æ›´æ–°ï¼")
                    output.append(f"ğŸ’¡ ä½¿ç”¨ sync_database å·¥å…·ä¸‹è½½æœ€æ–°æ•°æ®")
                else:
                    output.append(f"\nâœ… æœ¬åœ°æ•°æ®å·²æ˜¯æœ€æ–°")

                return "\n".join(output)
            else:
                return f"æ— æ³•è¿æ¥æ•°æ®æºï¼ŒçŠ¶æ€ç : {response.status_code}"

    except Exception as e:
        return f"æ£€æŸ¥æ›´æ–°å‡ºé”™: {str(e)}"


@app.tool()
async def sync_database() -> str:
    """
    ä»ShowJCRä¸‹è½½æœ€æ–°æ•°æ®åº“æ–‡ä»¶

    Returns:
        åŒæ­¥ç»“æœ
    """
    try:
        db_url = "https://raw.githubusercontent.com/hitfyd/ShowJCR/master/ä¸­ç§‘é™¢åˆ†åŒºè¡¨åŠJCRåŸå§‹æ•°æ®æ–‡ä»¶/jcr.db"

        output = ["ğŸ”„ å¼€å§‹åŒæ­¥æ•°æ®åº“..."]

        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.get(db_url, follow_redirects=True)

            if response.status_code == 200:
                # å¤‡ä»½æ—§æ•°æ®åº“
                backup_path = DATABASE_PATH + ".backup"
                if os.path.exists(DATABASE_PATH):
                    import shutil
                    shutil.copy2(DATABASE_PATH, backup_path)
                    output.append("ğŸ“¦ å·²å¤‡ä»½æ—§æ•°æ®åº“")

                # å†™å…¥æ–°æ•°æ®åº“
                with open(DATABASE_PATH, 'wb') as f:
                    f.write(response.content)

                new_size = len(response.content) / 1024 / 1024
                output.append(f"âœ… ä¸‹è½½å®Œæˆï¼Œå¤§å°: {new_size:.2f} MB")

                # éªŒè¯æ•°æ®åº“
                conn = sqlite3.connect(DATABASE_PATH)
                cursor = conn.cursor()
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = cursor.fetchall()
                conn.close()

                output.append(f"ğŸ“Š æ•°æ®è¡¨æ•°é‡: {len(tables)}")
                output.append("\nâœ… æ•°æ®åº“åŒæ­¥æˆåŠŸï¼")

                return "\n".join(output)
            else:
                return f"ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"

    except Exception as e:
        return f"åŒæ­¥å‡ºé”™: {str(e)}"


@app.tool()
async def get_available_categories(year: str = "2025") -> str:
    """
    è·å–å¯ç”¨çš„å­¦ç§‘åˆ†ç±»åˆ—è¡¨

    Args:
        year: æ•°æ®å¹´ä»½ï¼Œé»˜è®¤2025

    Returns:
        å¯ç”¨çš„å­¦ç§‘å¤§ç±»åˆ—è¡¨
    """
    try:
        conn = sqlite3.connect(db.db_path)
        cursor = conn.cursor()

        table_name = f"FQBJCR{year}"
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,))

        if not cursor.fetchone():
            conn.close()
            return f"æœªæ‰¾åˆ°{year}å¹´çš„æ•°æ®"

        cursor.execute(f"SELECT DISTINCT å¤§ç±» FROM {table_name} WHERE å¤§ç±» IS NOT NULL ORDER BY å¤§ç±»")
        categories = [row[0] for row in cursor.fetchall()]
        conn.close()

        output = [f"ğŸ“š å¯ç”¨å­¦ç§‘åˆ†ç±»ï¼ˆ{year}å¹´ï¼‰"]
        output.append("=" * 30)
        for i, cat in enumerate(categories, 1):
            output.append(f"{i}. {cat}")

        return "\n".join(output)

    except Exception as e:
        return f"è·å–åˆ†ç±»å‡ºé”™: {str(e)}"


@app.resource("jcr://database-info")
async def get_database_info() -> str:
    """è·å–æ•°æ®åº“åŸºæœ¬ä¿¡æ¯"""
    try:
        conn = sqlite3.connect(db.db_path)
        cursor = conn.cursor()
        
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [table[0] for table in cursor.fetchall()]
        
        info = ["ğŸ“Š JCRåˆ†åŒºè¡¨æ•°æ®åº“ä¿¡æ¯"]
        info.append("=" * 30)
        info.append(f"æ•°æ®åº“è·¯å¾„: {db.db_path}")
        info.append(f"æ•°æ®è¡¨æ•°é‡: {len(tables)}")
        info.append("\nğŸ“‹ å¯ç”¨æ•°æ®è¡¨:")
        
        for table in sorted(tables):
            cursor.execute(f"SELECT COUNT(*) FROM {table}")
            count = cursor.fetchone()[0]
            info.append(f"  â€¢ {table}: {count} æ¡è®°å½•")
        
        conn.close()
        return "\n".join(info)
    
    except Exception as e:
        return f"è·å–æ•°æ®åº“ä¿¡æ¯å‡ºé”™: {str(e)}"

@app.prompt()
async def journal_analysis_prompt(journal_name: str) -> str:
    """æœŸåˆŠåˆ†æä¸“ç”¨æç¤ºè¯æ¨¡æ¿"""
    return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯æœŸåˆŠåˆ†æä¸“å®¶ã€‚è¯·åŸºäºæä¾›çš„æœŸåˆŠæ•°æ®ï¼Œå¯¹æœŸåˆŠ {journal_name} è¿›è¡Œå…¨é¢åˆ†æï¼ŒåŒ…æ‹¬ï¼š

1. æœŸåˆŠåŸºæœ¬ä¿¡æ¯åˆ†æ
2. å½±å“å› å­å˜åŒ–è¶‹åŠ¿
3. åˆ†åŒºå˜åŒ–æƒ…å†µ
4. é¢„è­¦çŠ¶æ€è¯„ä¼°
5. æŠ•ç¨¿å»ºè®®

è¯·ç”¨ä¸“ä¸šã€å®¢è§‚çš„è¯­è¨€è¿›è¡Œåˆ†æï¼Œå¹¶ç»™å‡ºå…·ä½“çš„æŠ•ç¨¿å»ºè®®ã€‚
"""

if __name__ == "__main__":
    # è¿è¡ŒMCPæœåŠ¡å™¨
    print("ğŸš€ å¯åŠ¨JCRåˆ†åŒºè¡¨MCPæœåŠ¡å™¨...")
    print(f"ğŸ“Š æ•°æ®åº“è·¯å¾„: {DATABASE_PATH}")
    print("ğŸ”§ å¯ç”¨å·¥å…·:")
    print("  â€¢ search_journal - æœç´¢æœŸåˆŠä¿¡æ¯")
    print("  â€¢ get_partition_trends - è·å–åˆ†åŒºè¶‹åŠ¿")
    print("  â€¢ check_warning_journals - æŸ¥è¯¢é¢„è­¦æœŸåˆŠ")
    print("  â€¢ compare_journals - å¯¹æ¯”æœŸåˆŠ")
    print("  â€¢ filter_journals - æŒ‰æ¡ä»¶ç­›é€‰æœŸåˆŠ [æ–°å¢]")
    print("  â€¢ batch_query_journals - æ‰¹é‡æŸ¥è¯¢å¯¼å‡º [æ–°å¢]")
    print("  â€¢ check_data_update - æ£€æŸ¥æ•°æ®æ›´æ–° [æ–°å¢]")
    print("  â€¢ sync_database - åŒæ­¥æœ€æ–°æ•°æ® [æ–°å¢]")
    print("  â€¢ get_available_categories - è·å–å­¦ç§‘åˆ†ç±» [æ–°å¢]")
    print("ğŸ’¡ æç¤ºè¯æ¨¡æ¿: journal_analysis_prompt")
    print("ğŸ“‹ èµ„æº: jcr://database-info")
    print("\nâš¡ æœåŠ¡å™¨å¯åŠ¨ä¸­...")

    app.run(transport="stdio") 