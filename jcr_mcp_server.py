import asyncio
import sqlite3
import os
import json
from typing import Optional, Dict, List, Any
from dataclasses import dataclass
import httpx
from pathlib import Path

from mcp.server.fastmcp import FastMCP
from mcp.server.fastmcp import Context

# é…ç½®å¸¸é‡
DATABASE_PATH = "jcr.db"
DATA_UPDATE_URL = "https://raw.githubusercontent.com/hitfyd/ShowJCR/master/ä¸­ç§‘é™¢åˆ†åŒºè¡¨åŠJCRåŸå§‹æ•°æ®æ–‡ä»¶/"

@dataclass
class JournalInfo:
    """æœŸåˆŠä¿¡æ¯æ•°æ®ç±»"""
    journal_name: str
    impact_factor: Optional[float] = None
    partition: Optional[str] = None
    category: Optional[str] = None
    warning_status: Optional[str] = None
    ccf_level: Optional[str] = None
    year: Optional[str] = None

class JCRDatabase:
    """JCRæ•°æ®åº“ç®¡ç†ç±»"""
    
    def __init__(self, db_path: str = DATABASE_PATH):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        if not os.path.exists(self.db_path):
            # å¦‚æœæ•°æ®åº“ä¸å­˜åœ¨ï¼Œåˆ›å»ºåŸºæœ¬è¡¨ç»“æ„
            conn = sqlite3.connect(self.db_path)
            conn.close()
    
    def search_journal(self, journal_name: str, year: Optional[str] = None) -> List[JournalInfo]:
        """æœç´¢æœŸåˆŠä¿¡æ¯"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        results = []
        try:
            # è·å–æ‰€æœ‰è¡¨å
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [table[0] for table in cursor.fetchall()]
            
            # åœ¨å„ä¸ªè¡¨ä¸­æœç´¢æœŸåˆŠ
            for table in tables:
                try:
                    # æ£€æŸ¥è¡¨ç»“æ„
                    cursor.execute(f"PRAGMA table_info({table})")
                    columns = [col[1] for col in cursor.fetchall()]
                    
                    if 'Journal' not in columns:
                        continue
                    
                    # æ„å»ºæŸ¥è¯¢è¯­å¥
                    query = f"SELECT * FROM {table} WHERE Journal LIKE ? COLLATE NOCASE"
                    cursor.execute(query, (f"%{journal_name}%",))
                    
                    rows = cursor.fetchall()
                    column_names = [description[0] for description in cursor.description]
                    
                    for row in rows:
                        row_dict = dict(zip(column_names, row))
                        journal_info = self._parse_journal_info(row_dict, table)
                        if journal_info:
                            results.append(journal_info)
                
                except sqlite3.Error:
                    continue
        
        finally:
            conn.close()
        
        return results
    
    def _parse_journal_info(self, row_dict: Dict, table_name: str) -> Optional[JournalInfo]:
        """è§£ææ•°æ®åº“è¡Œä¸ºæœŸåˆŠä¿¡æ¯å¯¹è±¡"""
        try:
            journal_name = row_dict.get('Journal', '')
            
            # æ ¹æ®è¡¨ååˆ¤æ–­æ•°æ®ç±»å‹å’Œå¹´ä»½
            impact_factor = None
            partition = None
            category = None
            warning_status = None
            ccf_level = None
            year = None
            
            # è§£æå¹´ä»½
            if 'JCR' in table_name:
                year = table_name.replace('JCR', '')
                impact_factor = row_dict.get('IF', row_dict.get('Impact Factor'))
                partition = row_dict.get('Quartile', row_dict.get('åˆ†åŒº'))
                category = row_dict.get('Category', row_dict.get('ç±»åˆ«'))
            
            elif 'FQBJCR' in table_name:
                year = table_name.replace('FQBJCR', '')
                partition = row_dict.get('å¤§ç±»åˆ†åŒº', row_dict.get('Partition'))
                category = row_dict.get('å­¦ç§‘', row_dict.get('Subject'))
            
            elif 'GJQKYJMD' in table_name:
                year = table_name.replace('GJQKYJMD', '')
                warning_status = row_dict.get('é¢„è­¦ç­‰çº§', row_dict.get('Warning Level'))
            
            elif 'CCF' in table_name:
                year = table_name.replace('CCF', '')
                ccf_level = row_dict.get('CCFæ¨èç±»å‹', row_dict.get('CCF Level'))
                category = row_dict.get('é¢†åŸŸ', row_dict.get('Field'))
            
            return JournalInfo(
                journal_name=journal_name,
                impact_factor=impact_factor,
                partition=partition,
                category=category,
                warning_status=warning_status,
                ccf_level=ccf_level,
                year=year
            )
        
        except Exception:
            return None

# åˆå§‹åŒ–FastMCPæœåŠ¡å™¨
app = FastMCP("jcr-partition-server", port=8080)
db = JCRDatabase()

@app.tool()
async def search_journal(journal_name: str, year: Optional[str] = None) -> str:
    """
    æœç´¢æœŸåˆŠä¿¡æ¯ï¼ŒåŒ…æ‹¬å½±å“å› å­ã€åˆ†åŒºã€é¢„è­¦çŠ¶æ€ç­‰
    
    Args:
        journal_name: æœŸåˆŠåç§°ï¼ˆæ”¯æŒæ¨¡ç³Šæœç´¢ï¼‰
        year: æŒ‡å®šå¹´ä»½ï¼ˆå¯é€‰ï¼Œå¦‚2025ã€2024ã€2023ç­‰ï¼‰
    
    Returns:
        æœŸåˆŠçš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬å„å¹´ä»½çš„åˆ†åŒºã€å½±å“å› å­ç­‰æ•°æ®
    """
    try:
        results = db.search_journal(journal_name, year)
        
        if not results:
            return f"æœªæ‰¾åˆ°æœŸåˆŠ '{journal_name}' çš„ç›¸å…³ä¿¡æ¯"
        
        # æŒ‰æœŸåˆŠåç§°å’Œå¹´ä»½åˆ†ç»„æ•´ç†ç»“æœ
        grouped_results = {}
        for result in results:
            key = result.journal_name
            if key not in grouped_results:
                grouped_results[key] = []
            grouped_results[key].append(result)
        
        output = []
        for journal, infos in grouped_results.items():
            output.append(f"\nğŸ“š æœŸåˆŠåç§°: {journal}")
            output.append("=" * 50)
            
            # æŒ‰å¹´ä»½æ’åº
            infos.sort(key=lambda x: x.year or "0000", reverse=True)
            
            for info in infos:
                year_str = f"ã€{info.year}å¹´ã€‘" if info.year else "ã€æœªçŸ¥å¹´ä»½ã€‘"
                output.append(f"\n{year_str}")
                
                if info.impact_factor:
                    output.append(f"  ğŸ“Š å½±å“å› å­: {info.impact_factor}")
                
                if info.partition:
                    output.append(f"  ğŸ† åˆ†åŒº: {info.partition}")
                
                if info.category:
                    output.append(f"  ğŸ“– å­¦ç§‘ç±»åˆ«: {info.category}")
                
                if info.warning_status:
                    output.append(f"  âš ï¸ é¢„è­¦çŠ¶æ€: {info.warning_status}")
                
                if info.ccf_level:
                    output.append(f"  ğŸ… CCFæ¨èç­‰çº§: {info.ccf_level}")
        
        return "\n".join(output)
    
    except Exception as e:
        return f"æŸ¥è¯¢å‡ºé”™: {str(e)}"

@app.tool()
async def get_partition_trends(journal_name: str) -> str:
    """
    è·å–æœŸåˆŠåˆ†åŒºå˜åŒ–è¶‹åŠ¿
    
    Args:
        journal_name: æœŸåˆŠåç§°
    
    Returns:
        æœŸåˆŠå†å¹´åˆ†åŒºå˜åŒ–è¶‹åŠ¿åˆ†æ
    """
    try:
        results = db.search_journal(journal_name)
        
        if not results:
            return f"æœªæ‰¾åˆ°æœŸåˆŠ '{journal_name}' çš„ç›¸å…³ä¿¡æ¯"
        
        # æå–åˆ†åŒºä¿¡æ¯
        partition_data = []
        for result in results:
            if result.partition and result.year:
                partition_data.append((result.year, result.partition, result.journal_name))
        
        if not partition_data:
            return f"æœªæ‰¾åˆ°æœŸåˆŠ '{journal_name}' çš„åˆ†åŒºä¿¡æ¯"
        
        # æŒ‰å¹´ä»½æ’åº
        partition_data.sort(key=lambda x: x[0])
        
        output = [f"ğŸ“ˆ æœŸåˆŠåˆ†åŒºå˜åŒ–è¶‹åŠ¿åˆ†æ"]
        output.append("=" * 40)
        
        for year, partition, journal in partition_data:
            output.append(f"{year}å¹´: {partition}")
        
        # ç®€å•è¶‹åŠ¿åˆ†æ
        if len(partition_data) > 1:
            output.append("\nğŸ“Š è¶‹åŠ¿åˆ†æ:")
            first_partition = partition_data[0][1]
            last_partition = partition_data[-1][1]
            
            if "1åŒº" in last_partition or "Q1" in last_partition:
                output.append("âœ… è¯¥æœŸåˆŠä¿æŒåœ¨é¡¶çº§åˆ†åŒº")
            elif "4åŒº" in last_partition or "Q4" in last_partition:
                output.append("âš ï¸ è¯¥æœŸåˆŠåˆ†åŒºè¾ƒä½ï¼Œå‘è¡¨éœ€è°¨æ…")
            else:
                output.append("ğŸ“Š è¯¥æœŸåˆŠåˆ†åŒºç¨³å®šï¼Œå±äºä¸­ç­‰æ°´å¹³")
        
        return "\n".join(output)
    
    except Exception as e:
        return f"åˆ†æå‡ºé”™: {str(e)}"

@app.tool()
async def check_warning_journals(keywords: Optional[str] = None) -> str:
    """
    æŸ¥è¯¢å›½é™…æœŸåˆŠé¢„è­¦åå•
    
    Args:
        keywords: å…³é”®è¯ï¼ˆå¯é€‰ï¼Œç”¨äºç­›é€‰ç‰¹å®šæœŸåˆŠï¼‰
    
    Returns:
        é¢„è­¦æœŸåˆŠåˆ—è¡¨åŠå…¶é¢„è­¦åŸå› 
    """
    try:
        conn = sqlite3.connect(db.db_path)
        cursor = conn.cursor()
        
        # è·å–é¢„è­¦è¡¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'GJQKYJMD%'")
        warning_tables = [table[0] for table in cursor.fetchall()]
        
        if not warning_tables:
            return "æœªæ‰¾åˆ°é¢„è­¦æœŸåˆŠæ•°æ®è¡¨"
        
        output = ["ğŸš¨ å›½é™…æœŸåˆŠé¢„è­¦åå•æŸ¥è¯¢ç»“æœ"]
        output.append("=" * 40)
        
        for table in sorted(warning_tables, reverse=True):
            year = table.replace('GJQKYJMD', '')
            output.append(f"\nğŸ“… {year}å¹´é¢„è­¦åå•:")
            
            query = f"SELECT * FROM {table}"
            params = []
            
            if keywords:
                query += " WHERE Journal LIKE ? COLLATE NOCASE"
                params.append(f"%{keywords}%")
            
            cursor.execute(query, params)
            rows = cursor.fetchall()
            column_names = [description[0] for description in cursor.description]
            
            if rows:
                for row in rows:
                    row_dict = dict(zip(column_names, row))
                    journal_name = row_dict.get('Journal', 'æœªçŸ¥æœŸåˆŠ')
                    warning_reason = row_dict.get('é¢„è­¦åŸå› ', row_dict.get('é¢„è­¦ç­‰çº§', 'æœªçŸ¥åŸå› '))
                    output.append(f"  â€¢ {journal_name}: {warning_reason}")
            else:
                if keywords:
                    output.append(f"  æ— åŒ¹é… '{keywords}' çš„é¢„è­¦æœŸåˆŠ")
                else:
                    output.append("  è¯¥å¹´åº¦æ— é¢„è­¦æœŸåˆŠæ•°æ®")
        
        conn.close()
        return "\n".join(output)
    
    except Exception as e:
        return f"æŸ¥è¯¢é¢„è­¦æœŸåˆŠå‡ºé”™: {str(e)}"

@app.tool()
async def compare_journals(journal_list: str) -> str:
    """
    æ¯”è¾ƒå¤šä¸ªæœŸåˆŠçš„ç»¼åˆä¿¡æ¯
    
    Args:
        journal_list: æœŸåˆŠåç§°åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚"Nature,Science,Cell"
    
    Returns:
        å¤šä¸ªæœŸåˆŠçš„å¯¹æ¯”åˆ†æç»“æœ
    """
    try:
        journals = [j.strip() for j in journal_list.split(',')]
        
        if len(journals) < 2:
            return "è¯·è‡³å°‘æä¾›2ä¸ªæœŸåˆŠåç§°è¿›è¡Œæ¯”è¾ƒ"
        
        output = ["ğŸ“Š æœŸåˆŠå¯¹æ¯”åˆ†æç»“æœ"]
        output.append("=" * 50)
        
        all_results = {}
        for journal in journals:
            results = db.search_journal(journal)
            all_results[journal] = results
        
        # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
        output.append(f"\n{'æœŸåˆŠåç§°':<30} {'æœ€æ–°å½±å“å› å­':<15} {'æœ€æ–°åˆ†åŒº':<15} {'é¢„è­¦çŠ¶æ€':<15}")
        output.append("-" * 80)
        
        for journal, results in all_results.items():
            if not results:
                output.append(f"{journal:<30} {'æ— æ•°æ®':<15} {'æ— æ•°æ®':<15} {'æ— æ•°æ®':<15}")
                continue
            
            # è·å–æœ€æ–°æ•°æ®
            latest_if = "æ— æ•°æ®"
            latest_partition = "æ— æ•°æ®"
            warning_status = "æ­£å¸¸"
            
            for result in results:
                if result.impact_factor:
                    latest_if = str(result.impact_factor)
                if result.partition:
                    latest_partition = result.partition
                if result.warning_status:
                    warning_status = "âš ï¸é¢„è­¦"
                    break
            
            output.append(f"{journal:<30} {latest_if:<15} {latest_partition:<15} {warning_status:<15}")
        
        # æ¨èå»ºè®®
        output.append("\nğŸ’¡ æŠ•ç¨¿å»ºè®®:")
        for journal, results in all_results.items():
            if results:
                has_warning = any(r.warning_status for r in results)
                if has_warning:
                    output.append(f"  âŒ {journal}: è¯¥æœŸåˆŠåœ¨é¢„è­¦åå•ä¸­ï¼Œä¸å»ºè®®æŠ•ç¨¿")
                else:
                    latest_partition = None
                    for result in results:
                        if result.partition:
                            latest_partition = result.partition
                            break
                    
                    if latest_partition and ("1åŒº" in latest_partition or "Q1" in latest_partition):
                        output.append(f"  â­ {journal}: é¡¶çº§æœŸåˆŠï¼Œå¼ºçƒˆæ¨è")
                    elif latest_partition and ("2åŒº" in latest_partition or "Q2" in latest_partition):
                        output.append(f"  âœ… {journal}: ä¼˜è´¨æœŸåˆŠï¼Œæ¨èæŠ•ç¨¿")
                    else:
                        output.append(f"  ğŸ“ {journal}: å¯è€ƒè™‘æŠ•ç¨¿")
        
        return "\n".join(output)
    
    except Exception as e:
        return f"æ¯”è¾ƒåˆ†æå‡ºé”™: {str(e)}"

@app.resource("jcr://database-info")
async def get_database_info() -> str:
    """è·å–æ•°æ®åº“åŸºæœ¬ä¿¡æ¯"""
    try:
        conn = sqlite3.connect(db.db_path)
        cursor = conn.cursor()
        
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [table[0] for table in cursor.fetchall()]
        
        info = ["ğŸ“Š JCRåˆ†åŒºè¡¨æ•°æ®åº“ä¿¡æ¯"]
        info.append("=" * 30)
        info.append(f"æ•°æ®åº“è·¯å¾„: {db.db_path}")
        info.append(f"æ•°æ®è¡¨æ•°é‡: {len(tables)}")
        info.append("\nğŸ“‹ å¯ç”¨æ•°æ®è¡¨:")
        
        for table in sorted(tables):
            cursor.execute(f"SELECT COUNT(*) FROM {table}")
            count = cursor.fetchone()[0]
            info.append(f"  â€¢ {table}: {count} æ¡è®°å½•")
        
        conn.close()
        return "\n".join(info)
    
    except Exception as e:
        return f"è·å–æ•°æ®åº“ä¿¡æ¯å‡ºé”™: {str(e)}"

@app.prompt()
async def journal_analysis_prompt(journal_name: str) -> str:
    """æœŸåˆŠåˆ†æä¸“ç”¨æç¤ºè¯æ¨¡æ¿"""
    return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯æœŸåˆŠåˆ†æä¸“å®¶ã€‚è¯·åŸºäºæä¾›çš„æœŸåˆŠæ•°æ®ï¼Œå¯¹æœŸåˆŠ {journal_name} è¿›è¡Œå…¨é¢åˆ†æï¼ŒåŒ…æ‹¬ï¼š

1. æœŸåˆŠåŸºæœ¬ä¿¡æ¯åˆ†æ
2. å½±å“å› å­å˜åŒ–è¶‹åŠ¿
3. åˆ†åŒºå˜åŒ–æƒ…å†µ
4. é¢„è­¦çŠ¶æ€è¯„ä¼°
5. æŠ•ç¨¿å»ºè®®

è¯·ç”¨ä¸“ä¸šã€å®¢è§‚çš„è¯­è¨€è¿›è¡Œåˆ†æï¼Œå¹¶ç»™å‡ºå…·ä½“çš„æŠ•ç¨¿å»ºè®®ã€‚
"""

if __name__ == "__main__":
    # è¿è¡ŒMCPæœåŠ¡å™¨
    print("ğŸš€ å¯åŠ¨JCRåˆ†åŒºè¡¨MCPæœåŠ¡å™¨...")
    print(f"ğŸ“Š æ•°æ®åº“è·¯å¾„: {DATABASE_PATH}")
    print("ğŸ”§ å¯ç”¨å·¥å…·:")
    print("  â€¢ search_journal - æœç´¢æœŸåˆŠä¿¡æ¯")
    print("  â€¢ get_partition_trends - è·å–åˆ†åŒºè¶‹åŠ¿")
    print("  â€¢ check_warning_journals - æŸ¥è¯¢é¢„è­¦æœŸåˆŠ")
    print("  â€¢ compare_journals - å¯¹æ¯”æœŸåˆŠ")
    print("ğŸ’¡ æç¤ºè¯æ¨¡æ¿: journal_analysis_prompt")
    print("ğŸ“‹ èµ„æº: jcr://database-info")
    print("\nâš¡ æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    
    app.run(transport="stdio") 